import os
import re
import sys
import subprocess
from datetime import date, timedelta
import pandas as pd
import numpy as np
import streamlit as st
import psycopg2
from psycopg2.extras import RealDictCursor
import plotly.express as px
import plotly.graph_objects as go
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
from streamlit_echarts import st_echarts
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# --- í˜ì´ì§€ ì„¤ì • ë° ê³µí†µ í•¨ìˆ˜ ---

# Streamlit í˜ì´ì§€ì˜ ê¸°ë³¸ í™˜ê²½ì„ ì„¤ì •í•©ë‹ˆë‹¤
st.set_page_config(page_title="AI ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# Seaborn/Matplotlib ê·¸ë˜í”„ì˜ í•œê¸€ í°íŠ¸ ê¹¨ì§ ë°©ì§€ë¥¼ ìœ„í•œ ì „ì—­ ì„¤ì •ì…ë‹ˆë‹¤
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False
except Exception as e:
    st.error("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ë§‘ì€ ê³ ë”•' í°íŠ¸ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥ì…˜ì„ ìƒì„±í•˜ê³  ìºì‹±í•˜ì—¬ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤
@st.cache_resource
def get_conn():
    conn = psycopg2.connect(
        host=os.getenv("PGHOST", "localhost"),
        port=int(os.getenv("PGPORT", "5432")),
        dbname=os.getenv("PGDATABASE", "kurlydb"),
        user=os.getenv("PGUSER", "kurlyuser"),
        password=os.getenv("PGPASSWORD", "kurlypassword"),
        client_encoding='utf8'
    )
    return conn

# SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•˜ê³  ìºì‹±í•©ë‹ˆë‹¤
@st.cache_data(ttl=600)
def fetch_df(sql: str, params=None) -> pd.DataFrame:
    try:
        with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(sql, params or [])
            rows = cur.fetchall()
        return pd.DataFrame(rows)
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# --- Database Initialization ---
@st.cache_resource
def initialize_database():
    """
    Ensures all necessary tables are created in the database.
    Reads schema.sql and executes it.
    """
    try:
        schema_sql = """
        CREATE TABLE IF NOT EXISTS reviews (
          id BIGSERIAL PRIMARY KEY,
          product_name VARCHAR(255),
          content TEXT NOT NULL,
          review_date DATE,
          content_hash CHAR(64) NOT NULL UNIQUE,
          created_at TIMESTAMPTZ DEFAULT now()
        );
        CREATE TABLE IF NOT EXISTS review_analysis (
          id SERIAL PRIMARY KEY,
          review_id BIGINT NOT NULL REFERENCES reviews(id) ON DELETE CASCADE,
          model_name VARCHAR(50) NOT NULL,
          is_actual_review BOOLEAN NOT NULL,
          keywords TEXT[],
          categories TEXT[],
          sentiment_label VARCHAR(20),
          sentiment_score REAL,
          star_rating REAL,
          is_recipe_like BOOLEAN,
          summary TEXT,
          user_persona TEXT,
          improvement_suggestion TEXT,
          sentiment_reason TEXT,
          has_question BOOLEAN,
          raw_json JSONB,
          analyzed_at TIMESTAMPTZ DEFAULT now(),
          UNIQUE (review_id, model_name)
        );
        CREATE TABLE IF NOT EXISTS review_sentence_analysis (
          id SERIAL PRIMARY KEY,
          review_id BIGINT NOT NULL REFERENCES reviews(id) ON DELETE CASCADE,
          sent_index INTEGER NOT NULL,
          sentence TEXT,
          sentiment_label VARCHAR(20),
          sentiment_score REAL,
          model_name VARCHAR(50) NOT NULL,
          categories TEXT[],
          keywords TEXT[],
          analyzed_at TIMESTAMPTZ DEFAULT now(),
          UNIQUE (review_id, sent_index, model_name)
        );
        """
        with get_conn() as conn:
            with conn.cursor() as cur:
                cur.execute(schema_sql)
                # Also run alterations to ensure schema is up-to-date
                cur.execute("""
                    ALTER TABLE review_analysis
                    ADD COLUMN IF NOT EXISTS summary TEXT,
                    ADD COLUMN IF NOT EXISTS user_persona TEXT,
                    ADD COLUMN IF NOT EXISTS improvement_suggestion TEXT,
                    ADD COLUMN IF NOT EXISTS sentiment_reason TEXT,
                    ADD COLUMN IF NOT EXISTS has_question BOOLEAN;
                """
                )
                cur.execute("ALTER TABLE review_analysis ALTER COLUMN user_persona TYPE TEXT;")
                cur.execute("ALTER TABLE review_analysis DROP COLUMN IF EXISTS aspects;")
                cur.execute("""
                    ALTER TABLE review_sentence_analysis
                    ADD COLUMN IF NOT EXISTS categories TEXT[],
                    ADD COLUMN IF NOT EXISTS keywords TEXT[];
                """
                )
                conn.commit()
    except Exception as e:
        st.error(f"Database initialization failed: {e}")
        st.stop()

# Call the function at the start of the app
initialize_database()

st.title("âœ¨ AI ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•˜ê³  ìºì‹±í•©ë‹ˆë‹¤
@st.cache_data(ttl=600)
def fetch_df(sql: str, params=None) -> pd.DataFrame:
    try:
        with get_conn() as conn, conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(sql, params or [])
            rows = cur.fetchall()
        return pd.DataFrame(rows)
    except Exception as e:
        st.error(f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# AI ì´í‰ ìƒì„± í•¨ìˆ˜
@st.cache_data(ttl=3600, show_spinner="AIê°€ ë¦¬ë·°ë“¤ì„ ì¢…í•©í•˜ì—¬ ì´í‰ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
def generate_overall_summary(_summaries, _product_name):
    if not _summaries:
        return "ìš”ì•½í•  ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤."

    # LangChainì„ ì‚¬ìš©í•˜ì—¬ LLM ëª¨ë¸ê³¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
    try:
        llm = ChatOpenAI(model="gpt-4o", temperature=0.5, max_retries=2, request_timeout=120)
    except Exception as e:
        return f"AI ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}"

    prompt_text = (
        "ë‹¹ì‹ ì€ ê³ ê° ë¦¬ë·° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ '{product_name}' ìƒí’ˆì— ëŒ€í•œ ê³ ê° ë¦¬ë·° í•µì‹¬ ìš”ì•½ ëª¨ìŒì…ë‹ˆë‹¤. "
        "ì´ ìš”ì•½ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ, ê³ ê°ë“¤ì˜ ì „ë°˜ì ì¸ ë°˜ì‘ê³¼ í•µì‹¬ ì˜ê²¬ì„ ì¢…í•©í•˜ì—¬ 2~3 ë¬¸ì¥ì˜ ì™„ì„±ëœ í•œê¸€ ì´í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. "
        "ê¸ì •ì ì¸ ë¶€ë¶„ê³¼ ë¶€ì •ì ì¸ ë¶€ë¶„ì„ ê· í˜•ìˆê²Œ ì–¸ê¸‰í•˜ë˜, í™ë³´ ë¬¸êµ¬ê°€ ì•„ë‹Œ ê°ê´€ì ì¸ ë¶„ì„ê°€ì˜ ì‹œì„ ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
        "ë§Œì•½ ìš”ì•½ë¬¸ì˜ ì–‘ì´ ë„ˆë¬´ ì ê±°ë‚˜ ë‚´ìš©ì´ ë¶€ì¡±í•˜ë‹¤ë©´, ì£¼ì–´ì§„ ì •ë³´ë§Œìœ¼ë¡œ ê°„ë‹¨íˆ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n\n"
        "--- ë¦¬ë·° í•µì‹¬ ìš”ì•½ ëª¨ìŒ ---\n"
        "{review_summaries}\n"
        "---"
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a helpful market analysis assistant who summarizes customer feedback."),
        ("human", prompt_text)
    ])

    # ë¦¬ë·° ìš”ì•½ë¬¸ë“¤ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤
    formatted_summaries = "\n- ".join(_summaries)
    
    # LLM ì²´ì¸ì„ ì‹¤í–‰í•˜ì—¬ ì´í‰ì„ ìƒì„±í•©ë‹ˆë‹¤
    chain = prompt | llm
    try:
        response = chain.invoke({
            "product_name": _product_name,
            "review_summaries": formatted_summaries
        })
        return response.content
    except Exception as e:
        st.error(f"AI ì´í‰ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return "AI ì´í‰ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

# --- ë©”ì¸ ë„¤ë¹„ê²Œì´ì…˜ íƒ­ ---

# ì•±ì˜ ë©”ì¸ í™”ë©´ì„ êµ¬ì„±í•˜ëŠ” 3ê°œì˜ ìµœìƒìœ„ íƒ­ì„ ìƒì„±í•©ë‹ˆë‹¤
main_tab1, main_tab2, main_tab3 = st.tabs(["ğŸ“Š í†µí•© ëŒ€ì‹œë³´ë“œ", "ğŸ“¥ ë°ì´í„° ìˆ˜ì§‘", "ğŸ§  AI ë¶„ì„"])

# --- íƒ­ 1: í†µí•© ëŒ€ì‹œë³´ë“œ ---
with main_tab1:
    # --- ì‚¬ì´ë“œë°” í•„í„° ---
    with st.sidebar:
        st.header("âš™ï¸ í•„í„°")
        # DBì—ì„œ ìƒí’ˆ ëª©ë¡ì„ ê°€ì ¸ì™€ ì„ íƒ ì˜µì…˜ì„ ë§Œë“­ë‹ˆë‹¤
        df_products = fetch_df('''
            SELECT DISTINCT product_name 
            FROM reviews 
            WHERE product_name IS NOT NULL 
            ORDER BY product_name;
        ''')
        product_choices = ["ì „ì²´"] + (df_products["product_name"].tolist() if not df_products.empty else [])
        selected_product = st.selectbox("ìƒí’ˆ ì„ íƒ", product_choices)

        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ í•„í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        today = date.today()
        start_date = st.date_input("ì‹œì‘ì¼", today - timedelta(days=365))
        end_date = st.date_input("ì¢…ë£Œì¼", today)

        # í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ê¸°íƒ€ í•„í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤
        keyword = st.text_input("ë¦¬ë·° í‚¤ì›Œë“œ ê²€ìƒ‰ (ì„ íƒ ì‚¬í•­)")
        exclude_recipe = st.checkbox("ë ˆì‹œí”¼ì„± í›„ê¸° ì œì™¸", value=True)

        st.divider()
        if st.button("ğŸ”„ ìºì‹œ ì§€ìš°ê³  ìƒˆë¡œê³ ì¹¨"):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.rerun()

    # --- í•„í„°ë§ SQL ì¡°ê±´ ìƒì„± ---
    # ì„ íƒëœ í•„í„° ê°’ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ SQLì˜ WHERE ì ˆì„ ë™ì ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤
    params = [start_date, end_date]
    where_clauses = [
        "a.is_actual_review = true",
        "(r.review_date BETWEEN %s AND %s)"
    ]
    if selected_product != "ì „ì²´":
        where_clauses.append("r.product_name = %s")
        params.append(selected_product)
    if keyword:
        where_clauses.append("r.content ILIKE %s")
        params.append(f"%{keyword}%")
    if exclude_recipe:
        where_clauses.append("a.is_recipe_like = false")
    WHERE_SQL = " AND ".join(where_clauses)

    # --- ëŒ€ì‹œë³´ë“œ ìƒë‹¨ ìš”ì•½ ì •ë³´ ---
    # í¼ì¹¨/ì ‘ê¸° ê°€ëŠ¥í•œ ë©”ë‰´ë¡œ ì „ì²´ ë°ì´í„° í˜„í™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤
    with st.expander("ğŸ“Š ëŒ€ì‹œë³´ë“œ ì „ì²´ í˜„í™© ë³´ê¸°", expanded=True):
        # DBì˜ ê° í…Œì´ë¸”ë³„ ë°ì´í„° ì´ ê°œìˆ˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ë©”íŠ¸ë¦­ì…ë‹ˆë‹¤
        c1, c2, c3 = st.columns(3)
        try:
            reviews_count = fetch_df("SELECT COUNT(*) as count FROM reviews").iloc[0]['count']
            c1.metric("ìˆ˜ì§‘ëœ ë¦¬ë·° ìˆ˜", f"{reviews_count} ê±´")
        except Exception as e:
            c1.metric("ìˆ˜ì§‘ëœ ë¦¬ë·° ìˆ˜", "ì˜¤ë¥˜", help=str(e))
        try:
            analysis_count = fetch_df("SELECT COUNT(*) as count FROM review_analysis").iloc[0]['count']
            c2.metric("ë¶„ì„ëœ ë¦¬ë·° ìˆ˜", f"{analysis_count} ê±´")
        except Exception as e:
            c2.metric("ë¶„ì„ëœ ë¦¬ë·° ìˆ˜", "ì˜¤ë¥˜", help=str(e))
        try:
            sentence_count = fetch_df("SELECT COUNT(*) as count FROM review_sentence_analysis").iloc[0]['count']
            c3.metric("ë¶„ì„ëœ ë¬¸ì¥ ìˆ˜", f"{sentence_count} ê±´")
        except Exception as e:
            c3.metric("ë¶„ì„ëœ ë¬¸ì¥ ìˆ˜", "ì˜¤ë¥˜", help=str(e))
        
        st.divider()
        # ë¦¬ë·°ê°€ ë§ì€ ìƒìœ„ 5ê°œ ìƒí’ˆì˜ í•µì‹¬ ì§€í‘œë¥¼ ë³´ì—¬ì£¼ëŠ” ë¦¬ë”ë³´ë“œì…ë‹ˆë‹¤
        st.markdown("##### â­ ì£¼ìš” ìƒí’ˆ í˜„í™© (ë¦¬ë·° ìˆ˜ ê¸°ì¤€ TOP 5)")
        sql_leaderboard = f'''
            SELECT r.product_name, COUNT(r.id) as review_count,
                   COALESCE(ROUND(AVG(a.star_rating)::numeric, 2), 0) as avg_rating,
                   COALESCE(SUM(CASE WHEN a.sentiment_label = 'positive' THEN 1 ELSE 0 END), 0) as positive_reviews,
                   COALESCE(SUM(CASE WHEN a.sentiment_label = 'negative' THEN 1 ELSE 0 END), 0) as negative_reviews
            FROM reviews r JOIN review_analysis a ON r.id = a.review_id
            WHERE r.product_name IS NOT NULL AND a.is_actual_review = true
            GROUP BY r.product_name ORDER BY review_count DESC LIMIT 5
        '''
        df_leaderboard = fetch_df(sql_leaderboard)
        if not df_leaderboard.empty:
            df_leaderboard["sentiment_dist"] = df_leaderboard.apply(lambda row: [row['positive_reviews'], row['negative_reviews']], axis=1)
            # st.dataframeì˜ column_configë¥¼ ì‚¬ìš©í•˜ì—¬ í‘œ ë‚´ë¶€ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤
            st.dataframe(df_leaderboard, 
                column_config={
                    "product_name": st.column_config.TextColumn("ìƒí’ˆëª…", width="large"),
                    "review_count": st.column_config.NumberColumn("ë¦¬ë·° ìˆ˜", format="%d ê±´"),
                    "avg_rating": st.column_config.ProgressColumn("í‰ê·  ë³„ì ", format="%.2f", min_value=1.0, max_value=5.0),
                    "sentiment_dist": st.column_config.BarChartColumn("ê¸ì •/ë¶€ì • ë¶„í¬", y_min=0),
                    "positive_reviews": None, "negative_reviews": None
                },
                hide_index=True, use_container_width=True, column_order=["product_name", "review_count", "avg_rating", "sentiment_dist"]
            )
    st.divider()

    # --- ëŒ€ì‹œë³´ë“œ ìƒì„¸ íƒ­ ---
    # ì„ íƒëœ í•„í„° ì¡°ê±´ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì„ ë³´ì—¬ì£¼ëŠ” íƒ­ ë©”ë‰´ì…ë‹ˆë‹¤
    d_tab1, d_tab2, d_tab3, d_tab4, d_tab5 = st.tabs(["ğŸ“Š ìš”ì•½", "ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ë¶„ì„", "ğŸ”‘ í‚¤ì›Œë“œ ë¶„ì„", "âœï¸ ë¦¬ë·° ì›ë¬¸", "â“ ë„ì›€ë§"])
    
    # ìš”ì•½ íƒ­: ì„ íƒëœ ë°ì´í„°ì˜ í•µì‹¬ ì§€í‘œì™€ ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤
    with d_tab1:
        st.subheader(f"ğŸ“ˆ '{selected_product}' ìƒí’ˆ í•µì‹¬ ì§€í‘œ")
        sql_kpi = f"SELECT COALESCE(ROUND(AVG(a.star_rating)::numeric, 2), 0) as avg_rating, COUNT(r.id) as total_reviews, COALESCE(SUM(CASE WHEN a.sentiment_label = 'positive' THEN 1 ELSE 0 END), 0) as positive_reviews, COALESCE(SUM(CASE WHEN a.sentiment_label = 'negative' THEN 1 ELSE 0 END), 0) as negative_reviews FROM reviews r JOIN review_analysis a ON r.id = a.review_id WHERE {WHERE_SQL}"
        df_kpi = fetch_df(sql_kpi, params)
        if df_kpi.empty or df_kpi.iloc[0]["total_reviews"] == 0:
            st.warning("ì„ íƒí•˜ì‹  ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            kpi = df_kpi.iloc[0]
            total_sentiments = kpi["positive_reviews"] + kpi["negative_reviews"]
            pos_ratio = (kpi["positive_reviews"] / total_sentiments) * 100 if total_sentiments > 0 else 0
            avg_rating_value = float(kpi['avg_rating'])
            
            # KPIë¥¼ ì¹´ë“œ í˜•íƒœë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤
            col1, col2, col3 = st.columns(3)
            with col1:
                with st.container(border=True, height=150):
                    st.markdown("<p style='font-size: 18px; text-align: center; font-weight: bold;'>AI ì˜ˆì¸¡ í‰ê·  í‰ì </p>", unsafe_allow_html=True)
                    def rating_to_stars_html(rating, font_size=28):
                        rating = float(rating)
                        full_star = f'<span style="font-size: {font_size}px; color: #ffc107;">â˜…</span>'
                        empty_star = f'<span style="font-size: {font_size}px; color: #e0e0e0;">â˜†</span>'
                        full_stars = int(rating)
                        half_star = 1 if rating - full_stars >= 0.5 else 0
                        empty_stars = 5 - full_stars - half_star
                        return f"{full_star * (full_stars + half_star)}{empty_star * empty_stars}"
                    stars_html = rating_to_stars_html(avg_rating_value)
                    st.markdown(f"<div style='text-align: center;'>{stars_html}</div>", unsafe_allow_html=True)
                    st.markdown(f"<p style='text-align: center; font-size: 24px; font-weight: bold; margin-top: -5px;'>{avg_rating_value:.2f}</p>", unsafe_allow_html=True)
            with col2:
                with st.container(border=True, height=150):
                    st.markdown("<p style='font-size: 18px; text-align: center; font-weight: bold;'>ì´ ë¦¬ë·° ìˆ˜</p>", unsafe_allow_html=True)
                    st.markdown(f"<p style='font-size: 48px; text-align: center; font-weight: bold; line-height: 1.6;'>âœï¸ {kpi['total_reviews']}</p>", unsafe_allow_html=True)
            with col3:
                with st.container(border=True, height=150):
                    st.markdown("<p style='font-size: 18px; text-align: center; font-weight: bold;'>ê¸ì • ë¦¬ë·° ë¹„ìœ¨</p>", unsafe_allow_html=True)
                    st.markdown(f"<p style='font-size: 48px; text-align: center; font-weight: bold; line-height: 1.6;'>ğŸ™‚ {pos_ratio:.1f}%</p>", unsafe_allow_html=True)
            
            st.divider()

            # --- AI ì¢…í•© í‰ê°€ & ì£¼ìš” êµ¬ë§¤ì ìœ í˜• ---
            col1, col2 = st.columns([2, 1])
            with col1:
                st.subheader("ğŸ“ AI ì¢…í•© í‰ê°€")
                with st.container(border=True, height=250):
                    # í•„í„°ë§ëœ ë¦¬ë·°ë“¤ì˜ ê°œë³„ ìš”ì•½ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤
                    sql_summaries = f"SELECT a.summary FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.summary IS NOT NULL"
                    df_summaries = fetch_df(sql_summaries, params)
                    
                    if not df_summaries.empty:
                        summaries_list = df_summaries['summary'].tolist()
                        # AIë¥¼ í˜¸ì¶œí•˜ì—¬ ì¢…í•© ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤
                        overall_summary = generate_overall_summary(summaries_list, selected_product)
                        st.markdown(overall_summary)
                    else:
                        st.info("ì¢…í•© í‰ê°€ë¥¼ ìƒì„±í•˜ê¸°ì— ì¶©ë¶„í•œ ë¦¬ë·° ìš”ì•½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            with col2:
                st.subheader("ğŸ‘¥ ì£¼ìš” êµ¬ë§¤ì ìœ í˜•")
                with st.container(border=True, height=250):
                    sql_personas = f"SELECT user_persona, COUNT(*) as count FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.user_persona IS NOT NULL GROUP BY user_persona ORDER BY count DESC LIMIT 5"
                    df_personas = fetch_df(sql_personas, params)
                    if not df_personas.empty:
                        df_personas.set_index('user_persona', inplace=True)
                        st.bar_chart(df_personas['count'])
                    else:
                        st.info("êµ¬ë§¤ì ìœ í˜•ì„ ë¶„ì„í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

            st.divider()

            # --- AIê°€ ë¶„ì„í•œ ì£¼ìš” ê°•ì , ì•½ì  ë° ê°œì„  ì œì•ˆ ---
            c1, c2 = st.columns(2)
            with c1:
                st.subheader("ğŸ“Š ì£¼ìš” ê°•ì  ë° ì•½ì ")
                sql_cat_summary = f"SELECT cat, sentiment_label, COUNT(*) as review_count FROM review_analysis a JOIN reviews r ON a.review_id = r.id CROSS JOIN unnest(a.categories) as cat WHERE {WHERE_SQL} AND sentiment_label IN ('positive', 'negative') GROUP BY cat, sentiment_label"
                df_cat_summary = fetch_df(sql_cat_summary, params)
                if not df_cat_summary.empty:
                    with st.container(border=True, height=280):
                        col1_sub, col2_sub = st.columns(2)
                        with col1_sub:
                            st.markdown("<h5>ğŸ‘ ê°•ì </h5>", unsafe_allow_html=True)
                            pos_cats = df_cat_summary[df_cat_summary['sentiment_label'] == 'positive'].nlargest(3, 'review_count')
                            if not pos_cats.empty:
                                for index, row in pos_cats.iterrows():
                                    sql_keywords = f"SELECT keyword, COUNT(*) as count FROM (SELECT unnest(keywords) as keyword FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.sentiment_label = 'positive' AND %s = ANY(a.categories)) as kw WHERE keyword IS NOT NULL GROUP BY keyword ORDER BY count DESC LIMIT 3"
                                    df_keywords = fetch_df(sql_keywords, params + [row['cat']])
                                    keywords_str = ", ".join(df_keywords['keyword'].tolist()) if not df_keywords.empty else ""
                                    st.markdown(f"- **{row['cat']}** ({row['review_count']} ê±´) <br> &nbsp; *<span style='color: #666;'>{keywords_str}</span>*", unsafe_allow_html=True)
                            else:
                                st.info("ë¶„ì„ëœ ê°•ì ì´ ì—†ìŠµë‹ˆë‹¤.")
                        with col2_sub:
                            st.markdown("<h5>ğŸ‘ ì•½ì </h5>", unsafe_allow_html=True)
                            neg_cats = df_cat_summary[df_cat_summary['sentiment_label'] == 'negative'].nlargest(3, 'review_count')
                            if not neg_cats.empty:
                                for index, row in neg_cats.iterrows():
                                    sql_keywords = f"SELECT keyword, COUNT(*) as count FROM (SELECT unnest(keywords) as keyword FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.sentiment_label = 'negative' AND %s = ANY(a.categories)) as kw WHERE keyword IS NOT NULL GROUP BY keyword ORDER BY count DESC LIMIT 3"
                                    df_keywords = fetch_df(sql_keywords, params + [row['cat']])
                                    keywords_str = ", ".join(df_keywords['keyword'].tolist()) if not df_keywords.empty else ""
                                    st.markdown(f"- **{row['cat']}** ({row['review_count']} ê±´) <br> &nbsp; *<span style='color: #666;'>{keywords_str}</span>*", unsafe_allow_html=True)
                            else:
                                st.info("ë¶„ì„ëœ ì•½ì ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ê°•ì /ì•½ì  ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            
            with c2:
                st.subheader("ğŸ’¡ AIì˜ ê°œì„  ì œì•ˆ")
                sql_suggestions = f"SELECT DISTINCT improvement_suggestion FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.improvement_suggestion IS NOT NULL LIMIT 5"
                df_suggestions = fetch_df(sql_suggestions, params)
                with st.container(border=True, height=280):
                    if not df_suggestions.empty:
                        for suggestion in df_suggestions['improvement_suggestion']:
                            st.info(f"ğŸ’¡ {suggestion}")
                    else:
                        st.info("AIê°€ ì œì•ˆí•œ ê°œì„ ì ì´ ì—†ìŠµë‹ˆë‹¤.")

            st.divider()
            # ê¸/ë¶€ì • ë¹„ìœ¨ê³¼ í‰ì  ë¶„í¬ë¥¼ ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤
            c1, c2 = st.columns([1, 2])
            with c1:
                st.markdown("**ğŸ™‚ ê¸/ë¶€ì • ë¦¬ë·° ë¹„ìœ¨**")
                if total_sentiments > 0:
                    fig_pie = go.Figure(data=[go.Pie(labels=['ê¸ì •', 'ë¶€ì •'], values=[kpi["positive_reviews"], kpi["negative_reviews"]], hole=.6, marker_colors=['#3A7DFF', '#E9ECEF'], hoverinfo='label+percent', textinfo='none')])
                    fig_pie.update_layout(showlegend=False, margin=dict(t=0, b=0, l=0, r=0), annotations=[dict(text=f"<b>{pos_ratio:.1f}%</b>", x=0.5, y=0.5, font_size=28, showarrow=False, font_family="Arial")])
                    st.plotly_chart(fig_pie, use_container_width=True)
                else:
                    st.info("ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            with c2:
                st.markdown("**â­ AI ì˜ˆì¸¡ í‰ì  ë¶„í¬**")
                sql_rating_dist = f"SELECT star_rating, COUNT(*) as count FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.star_rating IS NOT NULL GROUP BY star_rating ORDER BY star_rating"
                df_rating_dist = fetch_df(sql_rating_dist, params)
                if not df_rating_dist.empty:
                    def rating_to_stars_label(rating):
                        rating = float(rating)
                        full_star = 'â˜…'; empty_star = 'â˜†'
                        full_stars = int(rating)
                        half_star = 1 if rating - full_stars >= 0.5 else 0
                        empty_stars = 5 - full_stars - half_star
                        return f"{full_star * full_stars}{full_star * half_star}{empty_star * empty_stars}"
                    df_rating_dist['star_label'] = df_rating_dist['star_rating'].apply(lambda r: f"{rating_to_stars_label(r)} ({r})")
                    fig = px.bar(df_rating_dist, x='star_label', y='count', color='star_rating', color_continuous_scale=px.colors.sequential.YlOrRd, text='count')
                    fig.update_layout(xaxis_title="AI Predicted Rating", yaxis_title="Review Count", showlegend=False, coloraxis_showscale=False, uniformtext_minsize=8, uniformtext_mode='hide')
                    fig.update_traces(textposition='outside', hovertemplate='<b>Rating: %{customdata[0]}</b><br>Count: %{y}<extra></extra>', customdata=df_rating_dist[['star_rating']])
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ë¶„í¬ë¥¼ ê·¸ë¦¬ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    # ì¹´í…Œê³ ë¦¬ ë¶„ì„ íƒ­: ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°ì´í„°ë¥¼ ì‹¬ì¸µ ë¶„ì„í•©ë‹ˆë‹¤
    with d_tab2:
        st.subheader("ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ë¶„ì„")
        st.markdown("**ì¹´í…Œê³ ë¦¬ë³„ ê¸/ë¶€ì • ë¦¬ë·° ë¹„ìœ¨**")
        sql_cat_sentiment = f"SELECT cat, SUM(CASE WHEN sentiment_label = 'positive' THEN 1 ELSE 0 END) as positive, SUM(CASE WHEN sentiment_label = 'negative' THEN 1 ELSE 0 END) as negative FROM review_analysis a JOIN reviews r ON a.review_id = r.id CROSS JOIN unnest(a.categories) as cat WHERE {WHERE_SQL} AND a.categories IS NOT NULL GROUP BY cat HAVING COUNT(*) > 2"
        df_cat_sentiment = fetch_df(sql_cat_sentiment, params)
        if not df_cat_sentiment.empty:
            df_cat_sentiment['total'] = df_cat_sentiment['positive'] + df_cat_sentiment['negative']
            df_cat_sentiment['pos_ratio'] = (df_cat_sentiment['positive'] / df_cat_sentiment['total']) * 100
            df_cat_sentiment['neg_ratio'] = (df_cat_sentiment['negative'] / df_cat_sentiment['total']) * 100
            fig_cat_bar = go.Figure()
            fig_cat_bar.add_trace(go.Bar(y=df_cat_sentiment['cat'], x=df_cat_sentiment['pos_ratio'], name='ê¸ì •', orientation='h', marker_color='#4CAF50'))
            fig_cat_bar.add_trace(go.Bar(y=df_cat_sentiment['cat'], x=df_cat_sentiment['neg_ratio'], name='ë¶€ì •', orientation='h', marker_color='#F44336'))
            fig_cat_bar.update_layout(barmode='stack', yaxis_title="ì¹´í…Œê³ ë¦¬", xaxis_title="ë¹„ìœ¨ (%)", yaxis=dict(autorange="reversed"))
            st.plotly_chart(fig_cat_bar, use_container_width=True)
        else:
            st.info("ì¹´í…Œê³ ë¦¬ë³„ ê¸/ë¶€ì • ë¹„ìœ¨ì„ ë¶„ì„í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        st.divider()
        st.markdown("**ì¹´í…Œê³ ë¦¬ë³„ AI ì˜ˆì¸¡ í‰ì  ë¶„í¬**")
        sql_cat_dist = f"SELECT unnest(a.categories) as category, a.star_rating, COUNT(*) as count FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.star_rating IS NOT NULL AND a.categories IS NOT NULL AND array_length(a.categories, 1) > 0 GROUP BY category, a.star_rating"
        df_cat_dist = fetch_df(sql_cat_dist, params)
        if not df_cat_dist.empty:
            pivot_df_counts = df_cat_dist.pivot_table(index='category', columns='star_rating', values='count', fill_value=0)
            row_sums = pivot_df_counts.sum(axis=1)
            safe_row_sums = row_sums.replace(0, 1)
            pivot_df_perc = pivot_df_counts.div(safe_row_sums, axis=0) * 100
            categories = pivot_df_perc.index.tolist()
            star_ratings = sorted(pivot_df_perc.columns.tolist())
            colors = ['#d73027', '#fc8d59', '#fee090', '#91bfdb', '#4575b4']
            star_color_map = {1.0: colors[0], 1.5: colors[0], 2.0: colors[1], 2.5: colors[1], 3.0: colors[2], 3.5: colors[2], 4.0: colors[3], 4.5: colors[3], 5.0: colors[4]}
            series = []
            for rating in star_ratings:
                series.append({"name": f'{rating}ì ', "type": 'bar', "stack": 'total', "label": {"show": False}, "emphasis": {"focus": 'series'}, "data": [round(x, 1) for x in pivot_df_perc[rating].tolist()], "itemStyle": {"color": star_color_map.get(rating, '#ccc')}})
            options = {"tooltip": {"trigger": "axis", "axisPointer": {"type": "shadow"}}, "legend": {"data": [s['name'] for s in series]}, "grid": {"left": "3%", "right": "4%", "bottom": "3%", "containLabel": True}, "xAxis": {"type": "value", "max": 100}, "yAxis": {"type": "category", "data": categories}, "series": series}
            st_echarts(options=options, height=f"{len(categories) * 50 + 100}px")
        else:
            st.info("ì¹´í…Œê³ ë¦¬ë³„ í‰ì  ë¶„í¬ë¥¼ ë¶„ì„í•˜ê¸°ì— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        st.divider()
        st.markdown("**ì¹´í…Œê³ ë¦¬ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ë° ë¦¬ë·°**")
        if not df_cat_sentiment.empty:
            selected_cat = st.selectbox("ë¶„ì„í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ", df_cat_sentiment['cat'].unique(), key="category_selector")
            if selected_cat:
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown(f"**ê¸ì •/ë¶€ì • ëŒ€í‘œ í‚¤ì›Œë“œ**")
                    sql_cat_kw = f"SELECT sentiment_label, keyword, COUNT(*) as count FROM (SELECT unnest(keywords) as keyword, sentiment_label FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND %s = ANY(a.categories) AND a.keywords IS NOT NULL) as kw_sent WHERE sentiment_label IN ('positive', 'negative') GROUP BY sentiment_label, keyword ORDER BY count DESC LIMIT 10"
                    df_cat_kw = fetch_df(sql_cat_kw, params + [selected_cat])
                    st.dataframe(df_cat_kw, use_container_width=True)
                with c2:
                    st.markdown(f"**ëŒ€í‘œ ê¸ì •/ë¶€ì • ë¦¬ë·°**")
                    sql_cat_rev = f"SELECT content, sentiment_label, star_rating FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND %s = ANY(a.categories) ORDER BY sentiment_score DESC LIMIT 1"
                    df_pos_rev = fetch_df(sql_cat_rev, params + [selected_cat])
                    if not df_pos_rev.empty: st.success(f"**[ê¸ì •]** {df_pos_rev.iloc[0]['content']}")
                    sql_cat_rev_neg = sql_cat_rev.replace("DESC", "ASC")
                    df_neg_rev = fetch_df(sql_cat_rev_neg, params + [selected_cat])
                    if not df_neg_rev.empty: st.error(f"**[ë¶€ì •]** {df_neg_rev.iloc[0]['content']}")
        else:
            st.info("ë¨¼ì € ìœ„ì—ì„œ ì¹´í…Œê³ ë¦¬ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")

    with d_tab3:
        st.subheader("ğŸ”‘ í‚¤ì›Œë“œ ìƒì„¸ ë¶„ì„")
        st.markdown("**ê¸ì • vs ë¶€ì • ë¦¬ë·° í•µì‹¬ í‚¤ì›Œë“œ**")
        sql_keywords = f"SELECT unnest(keywords) as keyword, sentiment_label FROM review_analysis a JOIN reviews r ON a.review_id = r.id WHERE {WHERE_SQL} AND a.keywords IS NOT NULL AND sentiment_label IN ('positive', 'negative')"
        df_keywords = fetch_df(sql_keywords, params)
        if not df_keywords.empty:
            c1, c2 = st.columns(2)
            try:
                font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
                pos_text = " ".join(df_keywords[df_keywords['sentiment_label'] == 'positive']['keyword'])
                neg_text = " ".join(df_keywords[df_keywords['sentiment_label'] == 'negative']['keyword'])
                with c1:
                    st.markdown("<p style='text-align: center;'>ğŸ™‚ ê¸ì • í‚¤ì›Œë“œ</p>", unsafe_allow_html=True)
                    if pos_text.strip():
                        wc_pos = WordCloud(font_path=font_path, background_color="white", width=400, height=300).generate(pos_text)
                        fig, ax = plt.subplots()
                        ax.imshow(wc_pos, interpolation='bilinear')
                        ax.axis("off")
                        st.pyplot(fig)
                    else:
                        st.info("ê¸ì • í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                with c2:
                    st.markdown("<p style='text-align: center;'>ğŸ™ ë¶€ì • í‚¤ì›Œë“œ</p>", unsafe_allow_html=True)
                    if neg_text.strip():
                        wc_neg = WordCloud(font_path=font_path, background_color="white", width=400, height=300).generate(neg_text)
                        fig, ax = plt.subplots()
                        ax.imshow(wc_neg, interpolation='bilinear')
                        ax.axis("off")
                        st.pyplot(fig)
                    else:
                        st.info("ë¶€ì • í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}. í°íŠ¸ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            st.info("í‚¤ì›Œë“œ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    with d_tab4:
        st.subheader("âœï¸ ë¦¬ë·° ì›ë¬¸ ë³´ê¸°")
        sql_raw = f"SELECT r.review_date as \"ë‚ ì§œ\", r.product_name as \"ìƒí’ˆëª…\", r.content as \"ë‚´ìš©\", a.star_rating as \"AIí‰ì \", a.sentiment_label as \"AIê°ì„±\", a.keywords as \"AIí‚¤ì›Œë“œ\" FROM reviews r JOIN review_analysis a ON r.id = a.review_id WHERE {WHERE_SQL} ORDER BY r.review_date DESC, r.id DESC LIMIT 500"
        df_raw = fetch_df(sql_raw, params)
        if not df_raw.empty:
            st.dataframe(df_raw, use_container_width=True)
            csv = df_raw.to_csv(index=False).encode('utf-8-sig')
            st.download_button("CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="review_analysis.csv", mime="text/csv")
        else:
            st.warning("í‘œì‹œí•  ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    with d_tab5:
        st.subheader("â“ ë„ì›€ë§")
        with st.expander("ìš©ì–´ ë° ë°ì´í„° ì •ë³´", expanded=True):
            st.markdown('''
            #### ìš©ì–´ ì •ì˜
            - **AI ì˜ˆì¸¡ í‰ì **: ë¦¬ë·° í…ìŠ¤íŠ¸ì˜ ê¸ì •/ë¶€ì • ë‰˜ì•™ìŠ¤, ì‚¬ìš©ëœ ì–´íœ˜ ë“±ì„ AIê°€ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ 1.0 ~ 5.0 ì‚¬ì´ì˜ ì ìˆ˜ë¡œ ë³€í™˜í•œ ê°’ì…ë‹ˆë‹¤.
            - **ê¸ì •/ë¶€ì • ë¦¬ë·°**: AIê°€ ë¦¬ë·°ì˜ ì „ì²´ì ì¸ ì–´ì¡°ë¥¼ 'positive', 'negative', 'neutral'ë¡œ ë¶„ë¥˜í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
            - **ì¹´í…Œê³ ë¦¬**: AIê°€ ë¦¬ë·° ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ 'ë§›', 'ê°€ê²©' ë“± ë¯¸ë¦¬ ì •ì˜ëœ ì£¼ì œ ì¤‘ ì–´ë–¤ ê²ƒê³¼ ê´€ë ¨ìˆëŠ”ì§€ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
            
            #### ë°ì´í„° ì›ë³¸
            - ë§ˆì¼“ì»¬ë¦¬ì˜ íŠ¹ì • ìƒí’ˆ í˜ì´ì§€ë“¤ì—ì„œ ìˆ˜ì§‘ëœ ê³µê°œ ì‚¬ìš©ì ë¦¬ë·°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.
            ''')
        st.markdown("### AI ë¦¬ë·° ë¶„ì„ ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•")

# --- íƒ­ 2: ë°ì´í„° ìˆ˜ì§‘ ---
with main_tab2:
    st.header("ğŸ“¥ ë°ì´í„° ìˆ˜ì§‘ (ì›¹ í¬ë¡¤ë§)")
    st.markdown("ì´ í˜ì´ì§€ì—ì„œ ë§ˆì¼“ì»¬ë¦¬ ì›¹ì‚¬ì´íŠ¸ë¡œë¶€í„° ìµœì‹  ë¦¬ë·° ë°ì´í„°ë¥¼ ìˆ˜ì§‘(í¬ë¡¤ë§)í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    if st.button("í¬ë¡¤ë§ ì‹œì‘í•˜ê¸°", type="primary"):
        script_path = "kurly.py"
        if not os.path.exists(script_path):
            st.error(f"`{script_path}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            log_area = st.empty()
            log_text = ""
            try:
                process = subprocess.Popen([sys.executable, "-u", script_path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', errors='replace')
                for line in iter(process.stdout.readline, ''):
                    log_text += line
                    log_area.code(log_text, language='log')
                process.stdout.close()
                process.wait()
                if process.returncode == 0:
                    st.success("âœ… í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
                else:
                    st.error("âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# --- íƒ­ 3: AI ë¶„ì„ ---
with main_tab3:
    st.header("ğŸ§  AI ë¦¬ë·° ë¶„ì„")
    st.markdown("ìˆ˜ì§‘ëœ ë¦¬ë·° ë°ì´í„°ë¥¼ AI ëª¨ë¸(GPT-4o)ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    if st.button("AI ë¶„ì„ ì‹œì‘í•˜ê¸°", type="primary"):
        script_path = "analyze.py"
        if not os.path.exists(script_path):
            st.error(f"`{script_path}` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("AI ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            log_area = st.empty()
            log_text = ""
            try:
                process = subprocess.Popen([sys.executable, "-u", script_path], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, encoding='utf-8', errors='replace')
                for line in iter(process.stdout.readline, ''):
                    log_text += line
                    log_area.code(log_text, language='log')
                process.stdout.close()
                process.wait()
                if process.returncode == 0:
                    st.success("âœ… AI ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
                else:
                    st.error("âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.divider()
    st.subheader("ì°¸ê³ : ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")
    if st.button("ëª¨ë“  ë°ì´í„° ì‚­ì œí•˜ê¸°", type="secondary"):
        try:
            with get_conn() as conn, conn.cursor() as cur:
                cur.execute("TRUNCATE TABLE reviews, review_analysis, review_sentence_analysis RESTART IDENTITY;")
                conn.commit()
            st.success("âœ… ëª¨ë“  ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.cache_data.clear()
            st.cache_resource.clear()
            st.rerun()
        except Exception as e:
            st.error(f"ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")